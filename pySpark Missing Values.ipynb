{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694eab8c",
   "metadata": {},
   "source": [
    "# pyspark Handling Missing Values\n",
    "\n",
    "- Dropping Columns.\n",
    "- Dropping Rows.\n",
    "- Various parameters in dropping functionalities.\n",
    "- Handling missing values by Mean, Median and Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08dc3022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61102910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name   Age   Salary           City  Gender\n",
      "0    Alice  25.0  50000.0       New York  Female\n",
      "1      Bob  30.0  60000.0    Los Angeles    Male\n",
      "2  Charlie   NaN  45000.0        Chicago    Male\n",
      "3    David   NaN      NaN        Houston    Male\n",
      "4     Emma  28.0  55000.0  San Francisco  Female\n",
      "5    Frank   NaN  70000.0         Boston    Male\n",
      "6    Grace  29.0  60000.0        Seattle  Female\n",
      "7    Henry  40.0  80000.0         Denver    Male\n",
      "8      Ivy  32.0      NaN         Austin  Female\n",
      "9     Jack  27.0  58000.0          Miami    Male\n",
      "DataFrame saved to sample_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Grace', 'Henry', 'Ivy', 'Jack'],\n",
    "    'Age': [25, 30, 22, np.nan, 28, 35, 29, 40, 32, 27],\n",
    "    'Salary': [50000, 60000, 45000, np.nan, 55000, 70000, 60000, 80000, np.nan, 58000],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'San Francisco', 'Boston', 'Seattle', 'Denver', 'Austin', 'Miami'],\n",
    "    'Gender': ['Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some missing values\n",
    "df.loc[2, 'Age'] = np.nan\n",
    "df.loc[3, 'Salary'] = np.nan\n",
    "df.loc[5, 'Age'] = np.nan\n",
    "df.loc[8, 'Salary'] = np.nan\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Function to save DataFrame to CSV file\n",
    "def save_to_csv(dataframe, file_path):\n",
    "    dataframe.to_csv(file_path, index=False)\n",
    "    print(f\"DataFrame saved to {file_path}\")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = 'sample_data.csv'\n",
    "save_to_csv(df, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1432c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('sample_data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f1723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-------------+------+\n",
      "|   Name| Age| Salary|         City|Gender|\n",
      "+-------+----+-------+-------------+------+\n",
      "|  Alice|25.0|50000.0|     New York|Female|\n",
      "|    Bob|30.0|60000.0|  Los Angeles|  Male|\n",
      "|Charlie|NULL|45000.0|      Chicago|  Male|\n",
      "|  David|NULL|   NULL|      Houston|  Male|\n",
      "|   Emma|28.0|55000.0|San Francisco|Female|\n",
      "|  Frank|NULL|70000.0|       Boston|  Male|\n",
      "|  Grace|29.0|60000.0|      Seattle|Female|\n",
      "|  Henry|40.0|80000.0|       Denver|  Male|\n",
      "|    Ivy|32.0|   NULL|       Austin|Female|\n",
      "|   Jack|27.0|58000.0|        Miami|  Male|\n",
      "+-------+----+-------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1806503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------+------+\n",
      "| Age| Salary|         City|Gender|\n",
      "+----+-------+-------------+------+\n",
      "|25.0|50000.0|     New York|Female|\n",
      "|30.0|60000.0|  Los Angeles|  Male|\n",
      "|NULL|45000.0|      Chicago|  Male|\n",
      "|NULL|   NULL|      Houston|  Male|\n",
      "|28.0|55000.0|San Francisco|Female|\n",
      "|NULL|70000.0|       Boston|  Male|\n",
      "|29.0|60000.0|      Seattle|Female|\n",
      "|40.0|80000.0|       Denver|  Male|\n",
      "|32.0|   NULL|       Austin|Female|\n",
      "|27.0|58000.0|        Miami|  Male|\n",
      "+----+-------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94cac49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-------------+------+\n",
      "|   Name| Age| Salary|         City|Gender|\n",
      "+-------+----+-------+-------------+------+\n",
      "|  Alice|25.0|50000.0|     New York|Female|\n",
      "|    Bob|30.0|60000.0|  Los Angeles|  Male|\n",
      "|Charlie|NULL|45000.0|      Chicago|  Male|\n",
      "|  David|NULL|   NULL|      Houston|  Male|\n",
      "|   Emma|28.0|55000.0|San Francisco|Female|\n",
      "|  Frank|NULL|70000.0|       Boston|  Male|\n",
      "|  Grace|29.0|60000.0|      Seattle|Female|\n",
      "|  Henry|40.0|80000.0|       Denver|  Male|\n",
      "|    Ivy|32.0|   NULL|       Austin|Female|\n",
      "|   Jack|27.0|58000.0|        Miami|  Male|\n",
      "+-------+----+-------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d06edf",
   "metadata": {},
   "source": [
    "## Dropping all the Null Rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f94fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+-------------+------+\n",
      "| Name| Age| Salary|         City|Gender|\n",
      "+-----+----+-------+-------------+------+\n",
      "|Alice|25.0|50000.0|     New York|Female|\n",
      "|  Bob|30.0|60000.0|  Los Angeles|  Male|\n",
      "| Emma|28.0|55000.0|San Francisco|Female|\n",
      "|Grace|29.0|60000.0|      Seattle|Female|\n",
      "|Henry|40.0|80000.0|       Denver|  Male|\n",
      "| Jack|27.0|58000.0|        Miami|  Male|\n",
      "+-----+----+-------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6492b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-------------+------+\n",
      "|   Name| Age| Salary|         City|Gender|\n",
      "+-------+----+-------+-------------+------+\n",
      "|  Alice|25.0|50000.0|     New York|Female|\n",
      "|    Bob|30.0|60000.0|  Los Angeles|  Male|\n",
      "|Charlie|NULL|45000.0|      Chicago|  Male|\n",
      "|  David|NULL|   NULL|      Houston|  Male|\n",
      "|   Emma|28.0|55000.0|San Francisco|Female|\n",
      "|  Frank|NULL|70000.0|       Boston|  Male|\n",
      "|  Grace|29.0|60000.0|      Seattle|Female|\n",
      "|  Henry|40.0|80000.0|       Denver|  Male|\n",
      "|    Ivy|32.0|   NULL|       Austin|Female|\n",
      "|   Jack|27.0|58000.0|        Miami|  Male|\n",
      "+-------+----+-------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0f6f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-------------+------+\n",
      "|   Name| Age| Salary|         City|Gender|\n",
      "+-------+----+-------+-------------+------+\n",
      "|  Alice|25.0|50000.0|     New York|Female|\n",
      "|    Bob|30.0|60000.0|  Los Angeles|  Male|\n",
      "|Charlie|NULL|45000.0|      Chicago|  Male|\n",
      "|   Emma|28.0|55000.0|San Francisco|Female|\n",
      "|  Frank|NULL|70000.0|       Boston|  Male|\n",
      "|  Grace|29.0|60000.0|      Seattle|Female|\n",
      "|  Henry|40.0|80000.0|       Denver|  Male|\n",
      "|    Ivy|32.0|   NULL|       Austin|Female|\n",
      "|   Jack|27.0|58000.0|        Miami|  Male|\n",
      "+-------+----+-------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##hreshold.\n",
    "\n",
    "df_pyspark.na.drop(how='any', thresh=4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79822ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+-------------+------+\n",
      "| Name| Age| Salary|         City|Gender|\n",
      "+-----+----+-------+-------------+------+\n",
      "|Alice|25.0|50000.0|     New York|Female|\n",
      "|  Bob|30.0|60000.0|  Los Angeles|  Male|\n",
      "| Emma|28.0|55000.0|San Francisco|Female|\n",
      "|Grace|29.0|60000.0|      Seattle|Female|\n",
      "|Henry|40.0|80000.0|       Denver|  Male|\n",
      "|  Ivy|32.0|   NULL|       Austin|Female|\n",
      "| Jack|27.0|58000.0|        Miami|  Male|\n",
      "+-----+----+-------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## subset\n",
    "\n",
    "df_pyspark.na.drop(how='any', subset=['Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e512c4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-------------+------+\n",
      "|   Name| Age| Salary|         City|Gender|\n",
      "+-------+----+-------+-------------+------+\n",
      "|  Alice|25.0|50000.0|     New York|Female|\n",
      "|    Bob|30.0|60000.0|  Los Angeles|  Male|\n",
      "|Charlie|NULL|45000.0|      Chicago|  Male|\n",
      "|  David|NULL|   NULL|      Houston|  Male|\n",
      "|   Emma|28.0|55000.0|San Francisco|Female|\n",
      "|  Frank|NULL|70000.0|       Boston|  Male|\n",
      "|  Grace|29.0|60000.0|      Seattle|Female|\n",
      "|  Henry|40.0|80000.0|       Denver|  Male|\n",
      "|    Ivy|32.0|   NULL|       Austin|Female|\n",
      "|   Jack|27.0|58000.0|        Miami|  Male|\n",
      "+-------+----+-------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Filing the missing values.\n",
    "\n",
    "df_pyspark.na.fill('Missing Value',['Salary','Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14dda229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age','Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['Age','Salary']]\n",
    "    ).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf682fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-------------+------+------------------+--------------+\n",
      "|   Name| Age| Salary|         City|Gender|       Age_imputed|Salary_imputed|\n",
      "+-------+----+-------+-------------+------+------------------+--------------+\n",
      "|  Alice|25.0|50000.0|     New York|Female|              25.0|       50000.0|\n",
      "|    Bob|30.0|60000.0|  Los Angeles|  Male|              30.0|       60000.0|\n",
      "|Charlie|NULL|45000.0|      Chicago|  Male|30.142857142857142|       45000.0|\n",
      "|  David|NULL|   NULL|      Houston|  Male|30.142857142857142|       59750.0|\n",
      "|   Emma|28.0|55000.0|San Francisco|Female|              28.0|       55000.0|\n",
      "|  Frank|NULL|70000.0|       Boston|  Male|30.142857142857142|       70000.0|\n",
      "|  Grace|29.0|60000.0|      Seattle|Female|              29.0|       60000.0|\n",
      "|  Henry|40.0|80000.0|       Denver|  Male|              40.0|       80000.0|\n",
      "|    Ivy|32.0|   NULL|       Austin|Female|              32.0|       59750.0|\n",
      "|   Jack|27.0|58000.0|        Miami|  Male|              27.0|       58000.0|\n",
      "+-------+----+-------+-------------+------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b0fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
